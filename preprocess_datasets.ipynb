{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from utils import *\n",
    "from modules.lingo_json_file_creator import LingoJsonFileCreator\n",
    "from modules.drivegpt4_bddx_json_file_creator import DriveGPT4BDDXJsonFileCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDD-X Paths\n",
    "BDD_X_DATASET_PATH = './datasets/bdd_x_dataset'\n",
    "BDD_X_TRAINING_VIDEOS_PATH = os.path.join(BDD_X_DATASET_PATH, 'train/videos')\n",
    "\n",
    "# LingoQA Paths\n",
    "LINGO_DATASET_PATH = './datasets/lingoqa_dataset'\n",
    "LINGO_ACTION_PATH = os.path.join(LINGO_DATASET_PATH, 'action')\n",
    "LINGO_SCENERY_PATH = os.path.join(LINGO_DATASET_PATH, 'scenery')\n",
    "LINGO_EVAL_PATH = os.path.join(LINGO_DATASET_PATH, 'evaluation')\n",
    "LINGO_IMAGES_PATH = os.path.join(LINGO_DATASET_PATH, 'images')\n",
    "LINGO_TRAIN_PATH = os.path.join(LINGO_DATASET_PATH, 'train')\n",
    "LINGO_VAL_PATH = os.path.join(LINGO_DATASET_PATH, 'val')\n",
    "\n",
    "# DriveGPT4 Paths\n",
    "DRIVE_BDDX_DATASET_PATH = './datasets/drivegpt4_dataset'\n",
    "DRIVE_BDDX_IMAGES_PATH = os.path.join(DRIVE_BDDX_DATASET_PATH, 'BDD_X_imgs_select')\n",
    "DRIVE_BDDX_VIDEOS_PATH = os.path.join(DRIVE_BDDX_DATASET_PATH, 'videos')\n",
    "\n",
    "\n",
    "# Our Paths\n",
    "OUR_DATASET_Path = './our_datasets'\n",
    "OUR_LINGO_DATASET_PATH = os.path.join(OUR_DATASET_Path, 'lingoqa_dataset')\n",
    "OUR_DRIVE_BDDX_DATASET_PATH = os.path.join(OUR_DATASET_Path, 'drivegpt4_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess LingoQA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Action Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action = pd.read_parquet(os.path.join(LINGO_ACTION_PATH, 'train.parquet'))\n",
    "df_action.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUR_LINGO_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "dataframe = df_action.groupby('segment_id')\n",
    "\n",
    "lingo_json_creator = LingoJsonFileCreator()\n",
    "json_data = lingo_json_creator.format_to_train(dataframe)\n",
    "lingo_json_creator.save_json(json_data, 'lingoqa_action.json', OUR_LINGO_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Code Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the dataset: 265323\n",
      "Number of questions in the JSON file: 265323\n",
      "They have the same questions.\n",
      "\n",
      "Number of answers in the dataset: 265323\n",
      "Number of answers in the JSON file: 265323\n",
      "They have the same answers.\n",
      "\n",
      "Number of videos in the dataset: 24491\n",
      "Number of videos in the JSON file: 24491\n",
      "They have the same videos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_path = os.path.join(OUR_LINGO_DATASET_PATH, 'lingoqa_action.json')\n",
    "\n",
    "questions_lst = df_action['question'].tolist()\n",
    "compare_num_questions(json_path, questions_lst)\n",
    "\n",
    "answers_lst = df_action['answer'].tolist()\n",
    "compare_num_answers(json_path, answers_lst)\n",
    "\n",
    "videos_lst = [video.replace('\\n', ',') for video in df_action['images'].astype(str).unique().tolist()]\n",
    "videos_lst = [ast.literal_eval(video)[0] for video in videos_lst]\n",
    "compare_num_videos(json_path, videos_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add `<image>` to my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lingo_action_json = os.path.join(OUR_LINGO_DATASET_PATH, 'lingoqa_action.json')\n",
    "\n",
    "add_token(lingo_action_json, '<image>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Scenery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenery = pd.read_parquet(os.path.join(LINGO_SCENERY_PATH, 'train.parquet'))\n",
    "df_scenery.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUR_LINGO_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "dataframe = df_scenery.groupby('segment_id')\n",
    "\n",
    "lingo_json_creator = LingoJsonFileCreator()\n",
    "json_data = lingo_json_creator.format_to_train(dataframe)\n",
    "lingo_json_creator.save_json(json_data, 'lingoqa_scenery.json', OUR_LINGO_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Code Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the dataset: 148506\n",
      "Number of questions in the JSON file: 148506\n",
      "They have the same questions.\n",
      "\n",
      "Number of answers in the dataset: 148506\n",
      "Number of answers in the JSON file: 148506\n",
      "They have the same answers.\n",
      "\n",
      "Number of videos in the dataset: 3508\n",
      "Number of videos in the JSON file: 3508\n",
      "They have the same videos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_path = os.path.join(OUR_LINGO_DATASET_PATH, 'lingoqa_scenery.json')\n",
    "\n",
    "questions_lst = df_scenery['question'].tolist()\n",
    "compare_num_questions(json_path, questions_lst)\n",
    "\n",
    "answers_lst = df_scenery['answer'].tolist()\n",
    "compare_num_answers(json_path, answers_lst)\n",
    "\n",
    "videos_lst = [video.replace('\\n', ',') for video in df_scenery['images'].astype(str).unique().tolist()]\n",
    "videos_lst = [ast.literal_eval(video)[0] for video in videos_lst]\n",
    "compare_num_videos(json_path, videos_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add `<image>` to my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lingo_scenery_json = os.path.join(OUR_LINGO_DATASET_PATH, 'lingoqa_scenery.json')\n",
    "\n",
    "add_token(lingo_scenery_json, '<image>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>images</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a938d25604410ccd63b60285919eaec</td>\n",
       "      <td>f2e4286e94457b8605069190e29f955a</td>\n",
       "      <td>[images/val/f2e4286e94457b8605069190e29f955a/0...</td>\n",
       "      <td>Is there a traffic light? If yes, what color i...</td>\n",
       "      <td>Yes, green.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a938d25604410ccd63b60285919eaec</td>\n",
       "      <td>f2e4286e94457b8605069190e29f955a</td>\n",
       "      <td>[images/val/f2e4286e94457b8605069190e29f955a/0...</td>\n",
       "      <td>Is there a traffic light? If yes, what color i...</td>\n",
       "      <td>Yes, a temporary traffic light. It is showing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id                        segment_id  \\\n",
       "0  1a938d25604410ccd63b60285919eaec  f2e4286e94457b8605069190e29f955a   \n",
       "1  1a938d25604410ccd63b60285919eaec  f2e4286e94457b8605069190e29f955a   \n",
       "\n",
       "                                              images  \\\n",
       "0  [images/val/f2e4286e94457b8605069190e29f955a/0...   \n",
       "1  [images/val/f2e4286e94457b8605069190e29f955a/0...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Is there a traffic light? If yes, what color i...   \n",
       "1  Is there a traffic light? If yes, what color i...   \n",
       "\n",
       "                                              answer  \n",
       "0                                        Yes, green.  \n",
       "1  Yes, a temporary traffic light. It is showing ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.read_parquet(os.path.join(LINGO_EVAL_PATH, 'val.parquet'))\n",
    "df_eval.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUR_LINGO_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "lingo_json_creator = LingoJsonFileCreator()\n",
    "json_data = lingo_json_creator.format_to_evaluate(df_eval)\n",
    "lingo_json_creator.save_json(json_data, 'lingoqa_eval.json', OUR_LINGO_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Code Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(OUR_LINGO_DATASET_PATH, 'lingoqa_eval.json')\n",
    "\n",
    "questions_lst = df_eval['question'].tolist()\n",
    "compare_num_questions(json_path, questions_lst, True)\n",
    "\n",
    "answers_lst = df_eval['answer'].tolist()\n",
    "compare_num_answers(json_path, answers_lst, True)\n",
    "\n",
    "videos_lst = [video.replace('\\n', ',') for video in df_eval['images'].astype(str).unique().tolist()]\n",
    "videos_lst = [ast.literal_eval(video)[0] for video in videos_lst]\n",
    "compare_num_videos(json_path, videos_lst, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess BDD-X DriveGPT4 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DRIVE_BDDX_DATASET_PATH, 'BDD_X_training_label.json'), 'r') as f:\n",
    "    drive_bddx_train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUR_DRIVE_BDDX_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "drive_json_creator = DriveGPT4BDDXJsonFileCreator()\n",
    "json_data = drive_json_creator.format_to_train(drive_bddx_train_data)\n",
    "drive_json_creator.save_json(json_data, 'drivegpt_bddx_training.json', OUR_DRIVE_BDDX_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Code Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the dataset: 114434\n",
      "Number of questions in the JSON file: 114434\n",
      "They have the same questions.\n",
      "\n",
      "Number of answers in the dataset: 114434\n",
      "Number of answers in the JSON file: 114434\n",
      "They have the same answers.\n",
      "\n",
      "Number of videos in the dataset: 14229\n",
      "Number of videos in the JSON file: 14229\n",
      "They have the same videos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_path = os.path.join(OUR_DRIVE_BDDX_DATASET_PATH, 'drivegpt_bddx_training.json')\n",
    "\n",
    "questions_lst = []\n",
    "answers_lst = []\n",
    "for data in drive_bddx_train_data:\n",
    "    for conv in data['conversations']:\n",
    "        if conv['from'] == 'human':\n",
    "            questions_lst.append(conv['value'])\n",
    "        else:\n",
    "            answers_lst.append(conv['value'])\n",
    "\n",
    "compare_num_questions(json_path, questions_lst)\n",
    "compare_num_answers(json_path, answers_lst)\n",
    "\n",
    "# video_lst = df_action['images'].astype(str).unique().tolist()\n",
    "videos_original = set()\n",
    "for data in drive_bddx_train_data:\n",
    "    videos_original.add(data['id'])\n",
    "\n",
    "compare_num_videos(json_path, list(videos_original), replace_this='_0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add `<image>` to my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivegpt_bddx_train_json = os.path.join(OUR_DRIVE_BDDX_DATASET_PATH, 'drivegpt_bddx_training.json')\n",
    "\n",
    "remove_tokens(drivegpt_bddx_train_json, ['\\n<video>'])\n",
    "add_token(drivegpt_bddx_train_json, '<image>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DRIVE_BDDX_DATASET_PATH, 'BDD_X_testing_label.json'), 'r') as f:\n",
    "    drive_bddx_test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUR_DRIVE_BDDX_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "drive_json_creator = DriveGPT4BDDXJsonFileCreator()\n",
    "json_data = drive_json_creator.format_to_evaluate(drive_bddx_test_data)\n",
    "drive_json_creator.save_json(json_data, 'drivegpt_bddx_testing.json', OUR_DRIVE_BDDX_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Code Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the dataset: 7244\n",
      "Number of questions in the JSON file: 7244\n",
      "They have the same questions.\n",
      "\n",
      "Number of answers in the dataset: 7244\n",
      "Number of answers in the JSON file: 7244\n",
      "They have the same answers.\n",
      "\n",
      "Number of videos in the dataset: 1811\n",
      "Number of videos in the JSON file: 1811\n",
      "They have the same videos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_path = os.path.join(OUR_DRIVE_BDDX_DATASET_PATH, 'drivegpt_bddx_testing.json')\n",
    "\n",
    "questions_lst = []\n",
    "answers_lst = []\n",
    "for data in drive_bddx_test_data:\n",
    "    for conv in data['conversations']:\n",
    "        if conv['from'] == 'human':\n",
    "            questions_lst.append(conv['value'])\n",
    "        else:\n",
    "            answers_lst.append(conv['value'])\n",
    "\n",
    "compare_num_questions(json_path, questions_lst, True)\n",
    "compare_num_answers(json_path, answers_lst, True)\n",
    "\n",
    "\n",
    "videos_original = set()\n",
    "for data in drive_bddx_test_data:\n",
    "    videos_original.add(data['id'])\n",
    "\n",
    "compare_num_videos(json_path, list(videos_original), '_0.png', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess BDD-X Original Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4590"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(BDD_X_DATASET_PATH, 'train.txt'), 'r') as f:\n",
    "    bdd_x_training_data = f.read().splitlines()\n",
    "    bdd_x_training_data = [line.split('_')[-1] for line in bdd_x_training_data]\n",
    "\n",
    "downloaded_videos = os.listdir(BDD_X_TRAINING_VIDEOS_PATH)\n",
    "downloaded_videos = [video.replace('.mov', '') for video in downloaded_videos]\n",
    "len(set(bdd_x_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(downloaded_videos).difference(set(bdd_x_training_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(BDD_X_DATASET_PATH, 'val.txt'), 'r') as f:\n",
    "    bdd_x_val_data = f.read().splitlines()\n",
    "    bdd_x_val_data = [line.split('_')[-1] for line in bdd_x_val_data]\n",
    "len(set(bdd_x_val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(bdd_x_val_data).intersection(set(downloaded_videos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BDD_X_DATASET_PATH, 'test.txt'), 'r') as f:\n",
    "    bdd_x_test_data = f.read().splitlines()\n",
    "    bdd_x_test_data = [line.split('_')[-1] for line in bdd_x_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(bdd_x_test_data).intersection(set(downloaded_videos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move videos to DriveGPT4 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DRIVE_BDDX_DATASET_PATH, 'BDD_X_training_label.json'), 'r') as f:\n",
    "    drive_bddx_train_data = json.load(f)\n",
    "    \n",
    "with open(os.path.join(DRIVE_BDDX_DATASET_PATH, 'BDD_X_testing_label.json'), 'r') as f:\n",
    "    drive_bddx_test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in the training dataset: 3438\n",
      "Number of videos in the testing dataset: 502\n",
      "Number of the intersected videos between downloaded videos and videos in training dataset: 3438\n",
      "Number of the intersection videos between downloaded videos and videos in testing dataset: 502\n"
     ]
    }
   ],
   "source": [
    "videos_train_lst = set()\n",
    "for data in drive_bddx_train_data:\n",
    "    videos_train_lst.add(data['id'].split('_')[1])\n",
    "\n",
    "videos_test_lst = set()\n",
    "for data in drive_bddx_test_data:\n",
    "    videos_test_lst.add(data['id'].split('_')[1])\n",
    "    \n",
    "\n",
    "print(f'Number of videos in the training dataset: {len(videos_train_lst)}')\n",
    "print(f'Number of videos in the testing dataset: {len(videos_test_lst)}')\n",
    "print(f'Number of the intersected videos between downloaded videos and videos in training dataset: {len(set(downloaded_videos).intersection(videos_train_lst))}')\n",
    "print(f'Number of the intersection videos between downloaded videos and videos in testing dataset: {len(set(downloaded_videos).intersection(videos_test_lst))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the videos to move: 3940\n",
      "Moved 0 video\n",
      "Moved 100 video\n",
      "Moved 200 video\n",
      "Moved 300 video\n",
      "Moved 400 video\n",
      "Moved 500 video\n",
      "Moved 600 video\n",
      "Moved 700 video\n",
      "Moved 800 video\n",
      "Moved 900 video\n",
      "Moved 1000 video\n",
      "Moved 1100 video\n",
      "Moved 1200 video\n",
      "Moved 1300 video\n",
      "Moved 1400 video\n",
      "Moved 1500 video\n",
      "Moved 1600 video\n",
      "Moved 1700 video\n",
      "Moved 1800 video\n",
      "Moved 1900 video\n",
      "Moved 2000 video\n",
      "Moved 2100 video\n",
      "Moved 2200 video\n",
      "Moved 2300 video\n",
      "Moved 2400 video\n",
      "Moved 2500 video\n",
      "Moved 2600 video\n",
      "Moved 2700 video\n",
      "Moved 2800 video\n",
      "Moved 2900 video\n",
      "Moved 3000 video\n",
      "Moved 3100 video\n",
      "Moved 3200 video\n",
      "Moved 3300 video\n",
      "Moved 3400 video\n",
      "Moved 3500 video\n",
      "Moved 3600 video\n",
      "Moved 3700 video\n",
      "Moved 3800 video\n",
      "Moved 3900 video\n"
     ]
    }
   ],
   "source": [
    "videos_to_move = list(set(downloaded_videos).intersection(videos_train_lst).union(set(downloaded_videos).intersection(videos_test_lst)))\n",
    "print(f'Length of the videos to move: {len(videos_to_move)}')\n",
    "\n",
    "os.makedirs(DRIVE_BDDX_VIDEOS_PATH, exist_ok=True)\n",
    "\n",
    "for idx, video in enumerate(videos_to_move):\n",
    "    if idx % 100 == 0:\n",
    "        print(f'Moved {idx} video')\n",
    "    video_src_path = os.path.join(BDD_X_TRAINING_VIDEOS_PATH, video+'.mov')\n",
    "    video_dst_path = os.path.join(DRIVE_BDDX_VIDEOS_PATH, video+'.mov')\n",
    "    shutil.copy2(video_src_path, video_dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3940"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(DRIVE_BDDX_VIDEOS_PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
